# Chapter 3. Property-Driven Training

## Motivation and Problem Statement

We finished the last chapter with a conjecture concerning
diminishing robustness verification success with increasing values of $\epsilon$.
Let us now see, using a concrete example, how soon the success rate declines.

The last exercise of the previous chapter gave us a property specification
for robustness of ``Fashion MNIST" models. We propose now to look into the statistics of verifying one of such models on 500 examples from the data set. To obtain quicker verification times, let us use a Fashion MNIST model with one input layer of $32$ neurons, and one output layer of $10$ neurons (the tutorial files contain the model if you wish to check it). Running Vehicle, we obtain the following success rates:

 $\epsilon = 0.01$ |    $\epsilon = 0.05$      |  $\epsilon = 0.1$   |   $\epsilon = 0.5$
:-----------------:|:-------------------------:|:-------------------:|:------------------
82.6 %   (413/500) | 29.8 % (149/500)          |  3.8 %  (19/500)    | 0 % (0/500)

As we see in the table, verifiability of the property deteriorates quickly with growing
$\epsilon$. Yet, for majority of practical applications, it is desirable to have a larger $\epsilon$,
as this increases the chance that new yet unseen data points will fall within the verified
subspaces of the input vector space.

Can we re-train the neural network to be more robust within a desirable $\epsilon$?
The long tradition of robustifying neural networks in machine learning has a few methods
ready, for example, to re-train the networks with new data set that was augmented with images within the
desired $\epsilon$-balls, or to generate adversarial examples (sample images closest to the decision boundary) within the given $\epsilon$-balls. We once again refer the reader to

* Marco Casadio, Ekaterina Komendantskaya, Matthew L. Daggitt, Wen Kokke, Guy Katz, Guy Amir, Idan Refaeli: Neural Network Robustness as a Verification Property: A Principled Case Study. CAV (1) 2022: 219-231.

for further discussion of these various methods.

In this tutorial, however, our interest is in _specification-driven_ neural network verification.
Our interest is thus in generating suitable loss functions directly from specifications. Crucially, this will allow us to work with arbitrary properties of neural networks, not only robustness.

Traditionally, translations from a given logical syntax to a loss function  are
 known as “differentiable logics", or DLs. One of the first attempts to translate propositional
logic specifications to loss functions was given in [@Xu et al. 2018]:

* Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van den Broeck. 2018. A Semantic Loss Function for Deep Learning with Symbolic Knowledge. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018 (Proceedings of Machine Learning Research, Vol. 80), Jennifer G. Dy and Andreas Krause (Eds.). PMLR, 5498–5507. <http://proceedings.mlr.press/v80/xu18h.html>

 and was generalised to a fragment of first-order logic in [@Fischer et al. 2019]:

* Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce Zhang, and Martin T. Vechev. 2019. DL2: Training and Querying Neural Networks with Logic. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA (Proceedings of Machine Learning Research, Vol. 97), Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.). PMLR, 1931–1941. <http://proceedings.mlr.press/v97/fischer19a.html>

 Later, this work was complemented by giving a fuzzy interpretation to DL by [@van Krieken et al. 2022]:

* Emile van Krieken, Erman Acar, and Frank van Harmelen. 2022. Analyzing Differentiable Fuzzy Logic Operators. Artif. Intell. 302 (2022), 103602. <https://doi.org/10.1016/j.artint.2021.103602>

 Slusarz et al. [2023] proposed generalisation for the
syntax and semantics of DL, with a view of encoding all previously presented DLs in one formal
system, and comparing their theoretical properties:

* Natalia Slusarz, Ekaterina Komendantskaya, Matthew L. Daggitt, Robert J. Stewart, and Kathrin Stark. 2023. Logic of Differentiable Logics: Towards a Uniform Semantics of DL. In LPAR-24: The International Conference on Logic for Programming, Artificial Intelligence and Reasoning.

Following this work, Vehicle contains translation to several loss functions available in the literature.
