## Chapter 1. Getting Started: the Vehicle's Language

In this chapter we will introduce some basic features of **Vehicle** as a programming language. We will use the famous *ACAS Xu verification challenge*,
first introduced in 2017 by Guy Katz et al. in *"Reluplex: An Efficient SMT Solver for Verifying -- Deep Neural Networks" (<https://arxiv.org/pdf/1702.01135.pdf>)*


### Standard Components of a Verification Problem

In the simplest verification scenario, we will need  a neural network $N : R^m \rightarrow R^n$, and a property of the network we wish to verify. Often, though not always, such property can be formulated based on our understanding of the domain where the neural network is used.
ACAS Xu stands for *Airborne Collision Avoidance System for unmanned  aircraft*. The objective is to analyse the airctaft's position and distance relative to other airctafts and give collision avoidance instructions.

In particular, the following measurements are of importance:
- $\rho$: feet **measuring the distance to intruder**,
- $\theta, \psi$: radians **measuring angle of intrusion**,
- $v_{own}, v_{vint}$: feet per second - **the speed of both aircrafts**,
- $\tau$: seconds - **time until loss of vertical separation**  

as the following picture illustrates: 
![ACAS Xu](acas_xu.png)

$\theta$ and $\psi$ are measured counter clockwise, and are always in the range $[âˆ’\pi, \pi]$.

Based on this data the neural network is to issue one of the following instructions: 
- Clear-of-Conflict (CoC), 
- weak left, 
- weak right, 
- strong left, 
- strong right.

Given six input parameters, and five instructions, a neural network $N_{AX} : R^6 \rightarrow R^5$ is trained, given the previous historic data. The exact architecture of the neural network , or its training mode are not important at the moment for our argument, and so we will omit this discussion for now. 

The original paper by Guy Katz lists ten properties, but for the sake of the illustration we will just consider the first of them:
*If the intruder is distant and is significantly slower than the ownship, the score of a COC advisory will always be below a certain fixed
threshold.*

### Basic Building Blocks in Vehicle 

#### Types

Unlike many Neural Network verifiers, Vehicle is a typeful language, and each specification file starts with declaring the types.
In the ACAS Xu case, these are

``` 
type InputVector = Vector Rat 6 
type OutputVector = Vector Rat 5
```

-- the types of vectors of rational numbers that the network will be taking as inputs and giving as outputs;
and ofcourse the type of the network itself:

``` 
@network
acasXu : InputVector -> OutputVector
```

The `Vector` type represents a mathematical vector, or in programming terms can be thought of as a fixed-length array. One potentially unusual aspect in Vehicle is that the size of the vector (i.e the number of items it contains) must be known statically at compile time. This allows Vehicle to check for the presence of out-of-bounds errors at compile time rather than run time.

The full type is therefore written as `Vector A n`, which represents the type of vectors with `n` elements of type `A`. For example, `Vector Rat 5` is a vector of length $10$ that contains rational numbers, and `Vector (List Nat) 2` is a vector of length $2$ that contains lists of natural numbers.

**Vehicle** in fact has a comprehensive support for programming with vectors, which we will see throughout this tutorial. But the interested reader may go ahead and check the documentation pages for vectors: <https://vehicle-lang.readthedocs.io/en/stable/language/vectors.html> 

Networks are declared by adding a `@network` annotation to a function declaration, as shown above. Note that although no implementation for the network is provided directly in the specification, `acasXu` can still be used in the specification as any other declared function would be.
This follows the **Vehicle** philosophy that specifications should be independent of any particular network, and should be able to be used to train/test/verify a range of candidate networks implementations.

#### Working with Vectors

Often, some amount of input or output pre-processing is expected when defining a specification. In the case of our example, it is assumed that neural network inputs and outputs are normalised, i.e. the network does not work directly with units like m/s. However, the specifications (and verification properties) we want to write should ideally  concern the original units. 

##### Problem space versus Input space

When we encounter similar problems later, we will say we encountered an instance of *problem space / input space mismatch*.
These occur because neural network models impose certain constraints on how a problem can be expressed.
In the simplest example above, values may need to be normalised. If we were to reason on input vectors
directly, we would be writing specifications in terms of the *input space*.
However, when reasoning about properties of neural networks, one often needs to refer to the original problem,
in the case specifications will be written about *problem space*. Let us see how this happens in practice. 

##### Normalisation

 As is common in machine learning, the network operates over
-- normalised values, rather than values in the problem space
-- (e.g. using standard units like m/s).
-- This is an issue for us, as we would like to write our specification in
-- terms of the problem space values .
-- Therefore before applying the network, we first have to normalise
-- the values in the problem space.

-- For clarity, we therefore define a new type synonym
-- for unnormalised input vectors which are in the problem space.
type UnnormalisedInputVector = Vector Rat 5

-- Next we define the minimum and maximum values that each input can take.
-- These correspond to the range of the inputs that the network is designed
-- to work over.
minimumInputValues : UnnormalisedInputVector
minimumInputValues = [0,0,0,0,0]

maximumInputValues : UnnormalisedInputVector
maximumInputValues = [60261.0, 2*pi, 2*pi, 1100.0, 1200.0]

-- We can therefore define a simple predicate saying whether a given input
-- vector is in the right range.
validInput : UnnormalisedInputVector -> Bool
validInput x = forall i . minimumInputValues ! i <= x ! i <= maximumInputValues ! i

-- Then the mean values that will be used to scale the inputs.
meanScalingValues : UnnormalisedInputVector
meanScalingValues = [19791.091, 0.0, 0.0, 650.0, 600.0]

-- We can now define the normalisation function that takes an input vector and
-- returns the unnormalised version.
normalise : UnnormalisedInputVector -> InputVector
normalise x = foreach i .
  (x ! i - meanScalingValues ! i) / (maximumInputValues ! i)

-- Using this we can define a new function that first normalises the input
-- vector and then applies the neural network.
normAcasXu : UnnormalisedInputVector -> OutputVector
normAcasXu x = acasXu (normalise x)




